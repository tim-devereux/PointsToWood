import sys
import argparse
import numpy as np
import pandas as pd
import os 

'''
Read and write PLY formatted point clouds--------------------------------------------------------------------------------------------
'''

def read_ply(fp, newline=None):

    encoding = 'ISO-8859-1' if sys.version_info > (3, 0) else None
    newline = '\n' if sys.platform == 'win32' and sys.version_info > (3, 0) else None

    with open(fp, encoding=encoding, newline=newline) as ply:
 
        length = 0
        prop = []
        dtype_map = {'uint16':'uint16', 'uint8':'uint8', 'double':'d', 'float64':'f8', 
                     'float32':'f4', 'float': 'f4', 'uchar': 'B', 'int':'i'}
        dtype = []
        fmt = 'binary'
    
        for i, line in enumerate(ply):
            length += len(line)
            split_line = line.split()
            if i == 1 and 'ascii' in line:
                fmt = 'ascii' 
            if 'element vertex' in line: N = int(split_line[2])
            if 'property' in line: 
                dtype.append(dtype_map[split_line[1]])
                prop.append(split_line[2])
            if 'element face' in line:
                raise Exception('.ply appears to be a mesh')
            if 'end_header' in line: break
    
        ply.seek(length)

        if fmt == 'binary':
            arr = np.fromfile(ply, dtype=','.join(dtype))
        else:
            arr = np.loadtxt(ply)
        df = pd.DataFrame(data=arr)
        df.columns = prop

    return df

def write_ply(output_name, pc, comments=[], preserve_raycloud_format=False):

    # Create a copy to avoid modifying original
    pc = pc.copy()
    
    # Remove duplicate columns if they exist
    if len(pc.columns) != len(set(pc.columns)):
        print(f"Warning: Removing duplicate columns from DataFrame")
        pc = pc.loc[:, ~pc.columns.duplicated()]
    
    cols = ['x', 'y', 'z']
    pc = pc.astype({'x': 'float64', 'y': 'float64', 'z': 'float64'})

    with open(output_name, 'w') as ply:

        ply.write("ply\n")
        ply.write('format binary_little_endian 1.0\n')
        
        # Check if this is raycloud format based on presence of raycloud-specific fields
        is_raycloud = any(col in pc.columns for col in ['time', 'nx', 'ny', 'nz', 'alpha'])
        
        if is_raycloud and preserve_raycloud_format:
            ply.write("comment generated by raycloudtools library\n")
        else:
            ply.write("comment Author: Phil Wilkes\n")
            
        for comment in comments:
            ply.write("comment {}\n".format(comment))
            
        if not (is_raycloud and preserve_raycloud_format):
            ply.write("obj_info generated with pcd2ply.py\n")
            
        ply.write("element vertex {}\n".format(len(pc)))
        ply.write("property double x\n")
        ply.write("property double y\n")
        ply.write("property double z\n")
        
        # Handle raycloud-specific properties in order
        if 'time' in pc.columns:
            pc = pc.astype({'time': 'float64'})
            ply.write("property double time\n")
            cols.append('time')
            
        # Handle normals
        for norm_col in ['nx', 'ny', 'nz']:
            if norm_col in pc.columns:
                pc = pc.astype({norm_col: 'float32'})
                ply.write("property float {}\n".format(norm_col))
                cols.append(norm_col)
        
        # Handle RGB colors
        if 'red' in pc.columns:
            cols += ['red', 'green', 'blue']
            pc[['red', 'green', 'blue']] = pc[['red', 'green', 'blue']].astype('uint8')
            ply.write("property uchar red\n")
            ply.write("property uchar green\n")
            ply.write("property uchar blue\n")
            
        # Handle alpha channel
        if 'alpha' in pc.columns:
            pc = pc.astype({'alpha': 'uint8'})
            ply.write("property uchar alpha\n")
            cols.append('alpha')
            
        # Handle classification field (add if not present and not preserving raycloud format)
        if not (is_raycloud and preserve_raycloud_format):
            if 'classification' not in pc.columns:
                pc['classification'] = 0  # Default unclassified
                
            if 'classification' in pc.columns:
                pc = pc.astype({'classification': 'uint8'})
                ply.write("property uchar classification\n")
                cols.append('classification')
            
        # Handle other fields (only if not raycloud or if explicitly in comments)
        if not (is_raycloud and preserve_raycloud_format):
            for col in pc.columns:
                if col in cols: continue
                try:
                    if col in ['reflectance', 'intensity']:
                        pc[col] = pc[col].astype('float32')
                        ply.write("property float {}\n".format(col))
                    else:
                        pc[col] = pc[col].astype('float64')
                        ply.write("property float64 {}\n".format(col))
                    cols += [col]
                except:
                    pass
                
        ply.write("end_header\n")

    with open(output_name, 'ab') as ply:
        ply.write(pc[cols].to_records(index=False).tobytes()) 


'''
Read and write PCD formatted point clouds----------------------------------------------------------------------------------------------------
'''

def read_pcd(fp):

    if (sys.version_info > (3, 0)):
        open_file = open(fp, encoding='ISO-8859-1')
    else:
        open_file = open(fp)

    with open_file as pcd:

        length = 0

        for i, line in enumerate(pcd.readlines()):
            length += len(line)
            if 'WIDTH' in line: N = int(line.split()[1])
            if 'FIELDS' in line: F = line.split()[1:]
            if 'DATA' in line:
                fmt = line.split()[1]
                break

        if fmt == 'binary':
            pcd.seek(length)
            arr = np.fromfile(pcd, dtype='f')

            arr = arr[:N*len(F)].reshape(-1, len(F))
            df = pd.DataFrame(arr, columns=F)

    if fmt == 'ascii':
        df = pd.read_csv(fp, sep=' ', names=F, skiprows=11)

    return df

def write_pcd(df, path, binary=True):

    columns = ['x', 'y', 'z', 'intensity']
    df.rename(columns={'scalar_intensity':'intensity'}, inplace=True)
    if 'intensity' not in df.columns: columns = columns[:3]

    with open(path, 'w') as pcd:

        pcd.write('# .PCD v0.7 - Point Cloud Data file format\n')
        pcd.write('VERSION 0.7\n')
        pcd.write('FIELDS ' + ' '.join(columns + ['\n']))
        pcd.write('SIZE ' + '4 ' * len(columns) + '\n')
        pcd.write('TYPE ' + 'F ' * len(columns) + '\n')
        pcd.write('COUNT ' + '1 ' * len(columns) + '\n')
        pcd.write('WIDTH {}\n'.format(len(df)))
        pcd.write('HEIGHT 1\n')
        pcd.write('VIEWPOINT 0 0 0 1 0 0 0\n')
        pcd.write('POINTS {}\n'.format(len(df)))
        pcd.write('DATA binary\n')

    with open(path, 'ab') as pcd:
        df[columns].values.astype('f4').tofile(pcd)


'''
Classification functions-------------------------------------------------------------------------------------------------------------
'''

def add_wood_classification(pc, wood_predictions, wood_threshold=0.5):
    """
    Add wood/non-wood classification to point cloud based on model predictions.
    Overwrites alpha channel with classification values.
    
    Args:
        pc (pd.DataFrame): Point cloud dataframe
        wood_predictions (np.array): Array of wood probability predictions (0-1)
        wood_threshold (float): Threshold above which points are classified as wood
        
    Returns:
        pd.DataFrame: Point cloud with alpha channel replaced by classification
        
    Classification codes:
        0: Unclassified
        1: Non-wood vegetation (foliage/leaves) 
        2: Wood
    """
    pc = pc.copy()
    
    # Use alpha channel for classification (overwrite it)
    if 'alpha' in pc.columns:
        pc['alpha'] = 0  # Initialize as unclassified
        pc.loc[wood_predictions >= wood_threshold, 'alpha'] = 2  # Wood
        pc.loc[wood_predictions < wood_threshold, 'alpha'] = 1   # Non-wood vegetation
    else:
        # Fallback to classification column if no alpha
        pc['classification'] = 0
        pc.loc[wood_predictions >= wood_threshold, 'classification'] = 2
        pc.loc[wood_predictions < wood_threshold, 'classification'] = 1
    
    return pc

def add_wood_confidence(pc, wood_predictions):
    """
    Add wood confidence scores to point cloud, overwriting alpha channel.
    
    Args:
        pc (pd.DataFrame): Point cloud dataframe
        wood_predictions (np.array): Array of wood probability predictions (0-1)
        
    Returns:
        pd.DataFrame: Point cloud with alpha channel replaced by confidence scores
    """
    pc = pc.copy()
    
    # Use alpha channel for confidence scores (overwrite it)
    if 'alpha' in pc.columns:
        # Scale confidence from 0-1 to 1-255 range for uchar (minimum value is 1)
        pc['alpha'] = (wood_predictions * 254 + 1).astype('uint8')
    else:
        # Fallback to confidence column if no alpha
        pc['confidence'] = wood_predictions
    
    return pc

'''
Read and Write functions-------------------------------------------------------------------------------------------------------------
'''

def load_file(filename, additional_headers=False, verbose=False):
    
    file_extension = os.path.splitext(filename)[1]
    headers = ['x', 'y', 'z']

    if file_extension == '.las' or file_extension == '.laz':

        import laspy

        inFile = laspy.read(filename)
        pc = np.vstack((inFile.x, inFile.y, inFile.z))
        pc = pd.DataFrame(data=pc.T, columns=['x', 'y', 'z'])

    elif file_extension == '.ply':
        pc = read_ply(filename)
        
    elif file_extension == '.pcd':
        pc = read_pcd(filename)
        
    else:
        raise Exception('point cloud format not recognised' + filename)

    original_num_points = len(pc)
    
    if verbose: print(f'read in {filename} with {len(pc)} points')
   
    if additional_headers:
        return pc, [c for c in pc.columns if c not in ['x', 'y', 'z']]
    else: return pc


def save_file(filename, pointcloud, additional_fields=[], verbose=False, preserve_raycloud_format=False):
    if verbose:
        print('Saving file:', filename)
        
    cols = ['x', 'y', 'z'] + additional_fields

    if filename.endswith('.las'):
        las = laspy.create(file_version="1.4", point_format=7)
        las.header.offsets = np.min(pointcloud[:, :3], axis=0)
        las.header.scales = [0.001, 0.001, 0.001]

        las.x = pointcloud[:, 0]
        las.y = pointcloud[:, 1]
        las.z = pointcloud[:, 2]

        if len(additional_fields) != 0:
            additional_fields = additional_fields[3:]

            #  The reverse step below just puts the headings in the preferred order. They are backwards without it.
            col_idxs = list(range(3, pointcloud.shape[1]))
            additional_fields.reverse()

            col_idxs.reverse()
            for header, i in zip(additional_fields, col_idxs):
                column = pointcloud[:, i]
                if header in ['red', 'green', 'blue']:
                    setattr(las, header, column)
                else:
                    las.add_extra_dim(laspy.ExtraBytesParams(name=header, type="f8"))
                    setattr(las, header, column)
        las.write(filename)
        if not verbose:
            print("Saved.")

    elif filename.endswith('.csv'):
        pd.DataFrame(pointcloud).to_csv(filename, header=None, index=None, sep=' ')
        if verbose: print("Saved to:", filename)

    elif filename.endswith('.ply'):

        if not isinstance(pointcloud, pd.DataFrame):
            cols = list(set(cols))
            pointcloud = pd.DataFrame(pointcloud, columns=cols)
        
        # For raycloud format, only keep specified columns
        if preserve_raycloud_format:
            # Keep core coordinates and specified additional fields only
            keep_cols = ['x', 'y', 'z'] + additional_fields
            # Also keep alpha if present (for classification/confidence)
            if 'alpha' in pointcloud.columns:
                keep_cols.append('alpha')
            # Filter to only existing columns
            keep_cols = [col for col in keep_cols if col in pointcloud.columns]
            pointcloud = pointcloud[keep_cols]
        
        write_ply(filename, pointcloud, preserve_raycloud_format=preserve_raycloud_format)
        if verbose: print("Saved to:", filename)